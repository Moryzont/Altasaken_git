ocr_engine <- tesseract::tesseract(language = "deu")
# OCR processing
ocr_text <- tesseract::ocr(image_path, engine = ocr_engine)
# Split text into sentences, but do not split if a solitary character or number is immediately before '.'
sentences <- unlist(strsplit(
ocr_text,
split = "(?<=\\.(?<!\\b[A-Za-z0-9]\\b\\.|\\bpp\\b\\.|\\bjf\\b\\.|\\bal\\b\\.))\\s+",
perl = TRUE
))
# Remove empty sentences and trim whitespace
sentences <- trimws(sentences[sentences != ""])
# Only create a dataframe if there are sentences
if (length(sentences) > 0) {
# Create a temporary dataframe
temp_df <- data.frame(
sentence = sentences,
page = page_number,
file_name = filename,
stringsAsFactors = FALSE
)
# Bind to main dataframe
all_sentences_df <- rbind(all_sentences_df, temp_df)
}
}
# Close the progress bar
close(pb)
return(all_sentences_df)
}
# Test with a subset of images
test_images <- image_files[1:5]
# Process the test images
test_result_df <- process_images(test_images)
# View the test results
print(test_result_df)
View(test_result_df)
library(magick)
install.packages("magick")
library(magick)
process_images <- function(image_paths) {
# Initialize an empty dataframe for all sentences
all_sentences_df <- data.frame(
sentence = character(),
page = integer(),
file_name = character(),
stringsAsFactors = FALSE
)
# Initialize progress bar
pb <- txtProgressBar(min = 0, max = length(image_paths), style = 3)
# Loop through each image path
for (i in seq_along(image_paths)) {
image_path <- image_paths[i]
# Update progress bar
setTxtProgressBar(pb, i)
# Check if the image file exists
if (!file.exists(image_path)) {
warning("The file does not exist at the specified path: ", image_path)
next
}
# Extract the file name
filename <- basename(image_path)
# Extract the page number from the filename
page_number <- as.integer(sub(".*_(\\d{3})\\.jpg$", "\\1", filename))
# If page_number is NA, handle it
if (is.na(page_number)) {
warning("Could not extract page number from filename: ", filename)
page_number <- NA
}
# Preprocess the image
preprocessed_img <- preprocess_image(image_path)
# Perform OCR on the preprocessed image
ocr_engine <- tesseract::tesseract(language = "deu")
ocr_text <- tesseract::ocr(preprocessed_img, engine = ocr_engine)
# Split text into sentences
sentences <- unlist(strsplit(
ocr_text,
split = "(?<=\\.(?<!\\b[A-Za-z0-9]\\b\\.|\\bpp\\b\\.|\\bjf\\b\\.|\\bal\\b\\.))\\s+",
perl = TRUE
))
# Remove empty sentences and trim whitespace
sentences <- trimws(sentences[sentences != ""])
# Only create a dataframe if there are sentences
if (length(sentences) > 0) {
# Create a temporary dataframe
temp_df <- data.frame(
sentence = sentences,
page = page_number,
file_name = filename,
stringsAsFactors = FALSE
)
# Bind to main dataframe
all_sentences_df <- rbind(all_sentences_df, temp_df)
}
}
# Close the progress bar
close(pb)
return(all_sentences_df)
}
# Set the path to the folder containing your images
image_folder <- '/Users/vetlewisloffsandring/Documents/tysk_arkiv/RZ 105_29943'
# Get a list of all JPEG images in the folder
image_files <- list.files(path = image_folder, pattern = "\\.jpg$", full.names = TRUE, ignore.case = TRUE)
# Test with a subset of images
test_images <- image_files[1:5]
# Process the test images
test_result_df <- process_images(test_images)
# Funksjon for å preprosessere bildene litt.
preprocess_image <- function(image_path) {
# Read the image using magick
img <- image_read(image_path)
# Convert to grayscale
img <- image_convert(img, colorspace = "gray")
# Adjust brightness and contrast (optional parameters)
img <- image_modulate(img, brightness = 100, saturation = 100, hue = 100)
# Enhance contrast
img <- image_contrast(img, sharpen = 1)
# Thresholding (binarization)
img <- image_threshold(img, type = "black", threshold = "50%")
# Reduce noise
img <- image_reducenoise(img, radius = 1)
# Sharpen the image
img <- image_sharpen(img, radius = 1, sigma = 0)
# Deskew the image (optional)
img <- image_deskew(img, threshold = 40)
# Return the processed image
return(img)
}
process_images <- function(image_paths) {
# Initialize an empty dataframe for all sentences
all_sentences_df <- data.frame(
sentence = character(),
page = integer(),
file_name = character(),
stringsAsFactors = FALSE
)
# Initialize progress bar
pb <- txtProgressBar(min = 0, max = length(image_paths), style = 3)
# Loop through each image path
for (i in seq_along(image_paths)) {
image_path <- image_paths[i]
# Update progress bar
setTxtProgressBar(pb, i)
# Check if the image file exists
if (!file.exists(image_path)) {
warning("The file does not exist at the specified path: ", image_path)
next
}
# Extract the file name
filename <- basename(image_path)
# Extract the page number from the filename
page_number <- as.integer(sub(".*_(\\d{3})\\.jpg$", "\\1", filename))
# If page_number is NA, handle it
if (is.na(page_number)) {
warning("Could not extract page number from filename: ", filename)
page_number <- NA
}
# Preprocess the image
preprocessed_img <- preprocess_image(image_path)
# Perform OCR on the preprocessed image
ocr_engine <- tesseract::tesseract(language = "deu")
ocr_text <- tesseract::ocr(preprocessed_img, engine = ocr_engine)
# Split text into sentences
sentences <- unlist(strsplit(
ocr_text,
split = "(?<=\\.(?<!\\b[A-Za-z0-9]\\b\\.|\\bpp\\b\\.|\\bjf\\b\\.|\\bal\\b\\.))\\s+",
perl = TRUE
))
# Remove empty sentences and trim whitespace
sentences <- trimws(sentences[sentences != ""])
# Only create a dataframe if there are sentences
if (length(sentences) > 0) {
# Create a temporary dataframe
temp_df <- data.frame(
sentence = sentences,
page = page_number,
file_name = filename,
stringsAsFactors = FALSE
)
# Bind to main dataframe
all_sentences_df <- rbind(all_sentences_df, temp_df)
}
}
# Close the progress bar
close(pb)
return(all_sentences_df)
}
# Set the path to the folder containing your images
image_folder <- '/Users/vetlewisloffsandring/Documents/tysk_arkiv/RZ 105_29943'
# Get a list of all JPEG images in the folder
image_files <- list.files(path = image_folder, pattern = "\\.jpg$", full.names = TRUE, ignore.case = TRUE)
###### TEST FØRST!!!! #####
# Test with a subset of images
test_images <- image_files[1:5]
# Process the test images
test_result_df <- process_images(test_images)
install.packages("magick")
install.packages("magick")
library(magick)
# Funksjon for å preprosessere bildene litt.
preprocess_image <- function(image_path) {
# Read the image using magick
img <- image_read(image_path)
# Convert to grayscale
img <- image_convert(img, colorspace = "gray")
# Adjust brightness and contrast
img <- image_modulate(img, brightness = 100, saturation = 100, hue = 100)
# Enhance contrast
img <- image_contrast(img, sharpen = 1)
# Thresholding (binarization)
img <- image_threshold(img, type = "black", threshold = "50%")
# Reduce noise
img <- image_reducenoise(img, radius = 1)
# Sharpen the image using unsharp mask
img <- image_unsharp_mask(img, radius = 1, sigma = 0.5, amount = 1, threshold = 0)
# Deskew the image (optional)
img <- image_deskew(img, threshold = 40)
# Return the processed image
return(img)
}
process_images <- function(image_paths) {
# Initialize an empty dataframe for all sentences
all_sentences_df <- data.frame(
sentence = character(),
page = integer(),
file_name = character(),
stringsAsFactors = FALSE
)
# Initialize progress bar
pb <- txtProgressBar(min = 0, max = length(image_paths), style = 3)
# Loop through each image path
for (i in seq_along(image_paths)) {
image_path <- image_paths[i]
# Update progress bar
setTxtProgressBar(pb, i)
# Check if the image file exists
if (!file.exists(image_path)) {
warning("The file does not exist at the specified path: ", image_path)
next
}
# Extract the file name
filename <- basename(image_path)
# Extract the page number from the filename
page_number <- as.integer(sub(".*_(\\d{3})\\.jpg$", "\\1", filename))
# If page_number is NA, handle it
if (is.na(page_number)) {
warning("Could not extract page number from filename: ", filename)
page_number <- NA
}
# Preprocess the image
preprocessed_img <- preprocess_image(image_path)
# Perform OCR on the preprocessed image
ocr_engine <- tesseract::tesseract(language = "deu")
ocr_text <- tesseract::ocr(preprocessed_img, engine = ocr_engine)
# Split text into sentences
sentences <- unlist(strsplit(
ocr_text,
split = "(?<=\\.(?<!\\b[A-Za-z0-9]\\b\\.|\\bpp\\b\\.|\\bjf\\b\\.|\\bal\\b\\.))\\s+",
perl = TRUE
))
# Remove empty sentences and trim whitespace
sentences <- trimws(sentences[sentences != ""])
# Only create a dataframe if there are sentences
if (length(sentences) > 0) {
# Create a temporary dataframe
temp_df <- data.frame(
sentence = sentences,
page = page_number,
file_name = filename,
stringsAsFactors = FALSE
)
# Bind to main dataframe
all_sentences_df <- rbind(all_sentences_df, temp_df)
}
}
# Close the progress bar
close(pb)
return(all_sentences_df)
}
# Set the path to the folder containing your images
image_folder <- '/Users/vetlewisloffsandring/Documents/tysk_arkiv/RZ 105_29943'
# Get a list of all JPEG images in the folder
image_files <- list.files(path = image_folder, pattern = "\\.jpg$", full.names = TRUE, ignore.case = TRUE)
###### TEST FØRST!!!! #####
# Test with a subset of images
test_images <- image_files[1:5]
# Process the test images
test_result_df <- process_images(test_images)
# Funksjon for å preprosessere bildene litt.
preprocess_image <- function(image_path) {
# Read the image using magick
img <- image_read(image_path)
# Convert to grayscale
img <- image_convert(img, colorspace = "gray")
# Adjust brightness and contrast
img <- image_modulate(img, brightness = 100, saturation = 100, hue = 100)
# Enhance contrast
img <- image_contrast(img, sharpen = 1)
# Thresholding (binarization)
img <- image_threshold(img, type = "black", threshold = "50%")
# Reduce noise
img <- image_reducenoise(img, radius = 1)
# Sharpen the image using unsharp mask
img <- image_enhance(img)
# Deskew the image (optional)
img <- image_deskew(img, threshold = 40)
# Return the processed image
return(img)
}
# Process the test images
test_result_df <- process_images(test_images)
# View the test results
print(test_result_df)
# Process the images
result_df <- process_images(image_files)
View(test_result_df)
preprocess_image <- function(image_path) {
# Read the image
img <- image_read(image_path)
# Convert to grayscale
img <- image_convert(img, colorspace = "gray")
# Adjust brightness and contrast (optional)
# You might adjust these values or comment them out
img <- image_modulate(img, brightness = 100, saturation = 100, hue = 100)
# Enhance contrast
img <- image_contrast(img, sharpen = 1)
# Remove thresholding
# img <- image_threshold(img, type = "black", threshold = "50%")
# Reduce noise
img <- image_reducenoise(img, radius = 1)
# Sharpen the image
img <- image_enhance(img)
# Return the processed image
return(img)
}
###### TEST FØRST!!!! #####
# Test with a subset of images
test_images <- image_files[1:5]
# Process the test images
test_result_df <- process_images(test_images)
# View the test results
print(test_result_df)
# Process the images
result_df <- process_images(image_files)
process_images <- function(image_paths) {
# Initialize an empty dataframe for all sentences with columns in the desired order
all_sentences_df <- data.frame(
page = integer(),
sentence = character(),
file_name = character(),
stringsAsFactors = FALSE
)
# Initialize progress bar
pb <- txtProgressBar(min = 0, max = length(image_paths), style = 3)
# Loop through each image path
for (i in seq_along(image_paths)) {
image_path <- image_paths[i]
# Update progress bar
setTxtProgressBar(pb, i)
# Check if the image file exists
if (!file.exists(image_path)) {
warning("The file does not exist at the specified path: ", image_path)
next
}
# Extract the file name
filename <- basename(image_path)
# Extract the page number from the filename
page_number <- as.integer(sub(".*_(\\d{3})\\.jpg$", "\\1", filename))
# If page_number is NA, handle it
if (is.na(page_number)) {
warning("Could not extract page number from filename: ", filename)
page_number <- NA
}
# Set the OCR language to German
ocr_engine <- tesseract::tesseract(language = "deu")
# OCR processing
ocr_text <- tesseract::ocr(image_path, engine = ocr_engine)
# Split text into sentences
sentences <- unlist(strsplit(
ocr_text,
split = "(?<=\\.(?<!\\b[A-Za-z0-9]\\b\\.|\\bpp\\b\\.|\\bjf\\b\\.|\\bal\\b\\.))\\s+",
perl = TRUE
))
# Remove empty sentences and trim whitespace
sentences <- trimws(sentences[sentences != ""])
# Only create a dataframe if there are sentences
if (length(sentences) > 0) {
# Create a temporary dataframe with columns in the desired order
temp_df <- data.frame(
page = page_number,
sentence = sentences,
file_name = filename,
stringsAsFactors = FALSE
)
# Bind to main dataframe
all_sentences_df <- rbind(all_sentences_df, temp_df)
}
}
# Close the progress bar
close(pb)
return(all_sentences_df)
}
# Set the path to the folder containing your images
image_folder <- '/Users/vetlewisloffsandring/Documents/tysk_arkiv/RZ 105_29943'
# Get a list of all JPEG images in the folder
image_files <- list.files(path = image_folder, pattern = "\\.jpg$", full.names = TRUE, ignore.case = TRUE)
###### TEST FØRST!!!! #####
# Test with a subset of images
test_images <- image_files[1:5]
# Process the test images
test_result_df <- process_images(test_images)
# View the test results
print(test_result_df)
View(test_result_df)
rm(list=ls()) # Clear de "Global Environment"
setwd("/Users/vetlewisloffsandring/Documents/Altasaken") # Den ser ikke slik ut på windows
options(scipen = 999)
options(encoding = "UTF-8")
library(tidyverse)
library(lubridate)
library(ggplot2)
library(scales)
renset_data_pre2023 <- read_csv("renset_data.csv")
renset_data_2023 <- read_csv("2023_conc_renset.csv")
renset_data_pre2023 <- subset(renset_data_pre2023, select = -c(...1, extracted_pattern))
renset_data_2023[, c(9:74)] <- sapply(renset_data_2023[, c(9:74)], as.numeric)
colnames(renset_data_2023) <- gsub("\\.", " ", colnames(renset_data_2023))
# Replace periods and hyphens with spaces in renset_data_pre2023
colnames(renset_data_pre2023) <- gsub("[.-]", " ", colnames(renset_data_pre2023))
# Replace periods and hyphens with spaces in renset_data_2023
colnames(renset_data_2023) <- gsub("[.-]", " ", colnames(renset_data_2023))
### TALL TRANSFORMASJONER
# Fjerner alt under 0.5
renset_data_trunkert <- renset_data %>%
mutate(across(where(is.numeric), ~if_else(. < 0.5, 0, .)))# Function to apply the condition on each row
renset_data <- rbind(renset_data_pre2023, renset_data_2023)
### TALL TRANSFORMASJONER
# Fjerner alt under 0.5
renset_data_trunkert <- renset_data %>%
mutate(across(where(is.numeric), ~if_else(. < 0.5, 0, .)))# Function to apply the condition on each row
#### Sjekker hvor mange det er av enkelte fraser##
altasaken_data <- renset_data %>%
filter(conc == "Altasaken" | conc == "Alta saken" | conc == "Alta-saken" | conc == "Alta-saka" | conc == "Alta saka")
renset_data_trunkert <- anti_join(renset_data_trunkert, altasaken_data, by = "conc")
antall_table <- renset_data_trunkert %>%
filter(year >= 1983) %>%
group_by(year) %>%
summarise(count = n())  # 'count' will hold the number of observations per year
ggplot(antall_table, aes(x = year, y = count)) +
geom_vline(aes(xintercept = year), linetype = "solid", alpha = 0.1) +  # Draw vertical lines for each year
# Add smoothed line first to be behind
geom_smooth(aes(color = "Smoothed"), method = "loess", se = FALSE, size = 1) +
# Add unsmoothed line on top
geom_line(aes(color = "Unsmoothed"), size = 1) +
# Adjust colors with adjusted alpha values
scale_color_manual(
values = c(
"Smoothed" = alpha("deepskyblue2", 0.4),
"Unsmoothed" = alpha("deepskyblue4", 0.9)
)
) +
# Customize x-axis
scale_x_continuous(breaks = seq(1983, 2022, by = 2)) +  # Adjust breaks to show every 2 years
# Add labels
labs(
title = "Yearly number of observations related to the Alta-controversy, 1983-2023.",
x = "Year",
y = "Total Number of Yearly Observations",
color = "Legend"
) +
# Customize legend
guides(color = guide_legend(override.aes = list(size = 1))) +
# Set plot theme
theme(
panel.background = element_rect(fill = 'bisque', color = 'bisque3'),
panel.grid.major = element_line(color = 'bisque3'),
panel.grid.minor = element_line(color = 'bisque'),
legend.background = element_rect(fill = 'bisque3'),
legend.key = element_rect(fill = 'bisque3', colour = 'bisque4'),
plot.background = element_rect(fill = 'bisque2')
)
ggplot(antall_table, aes(x = year, y = count)) +
geom_vline(aes(xintercept = year), linetype = "solid", alpha = 0.1) +  # Draw vertical lines for each year
# Add smoothed line first to be behind
geom_smooth(aes(color = "Smoothed"), method = "loess", se = FALSE, size = 1) +
# Add unsmoothed line on top
geom_line(aes(color = "Unsmoothed"), size = 1) +
# Adjust colors with adjusted alpha values
scale_color_manual(
values = c(
"Smoothed" = alpha("deepskyblue2", 0.4),
"Unsmoothed" = alpha("deepskyblue4", 0.9)
)
) +
# Customize x-axis
scale_x_continuous(breaks = seq(1983, 2023, by = 2)) +  # Adjust breaks to show every 2 years
# Add labels
labs(
title = "Yearly number of observations related to the Alta-controversy, 1983-2023.",
x = "Year",
y = "Total Number of Yearly Observations",
color = "Legend"
) +
# Customize legend
guides(color = guide_legend(override.aes = list(size = 1))) +
# Set plot theme
theme(
panel.background = element_rect(fill = 'bisque', color = 'bisque3'),
panel.grid.major = element_line(color = 'bisque3'),
panel.grid.minor = element_line(color = 'bisque'),
legend.background = element_rect(fill = 'bisque3'),
legend.key = element_rect(fill = 'bisque3', colour = 'bisque4'),
plot.background = element_rect(fill = 'bisque2')
)
